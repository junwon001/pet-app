from sentence_transformers import SentenceTransformer
import chromadb
import pandas as pd
import os

# ğŸš¨ KoELECTRA ê¸°ë°˜ ëª¨ë¸ë¡œ ë³€ê²½ ğŸš¨
# 'monologg/koelectra-base-v3-discriminator' ê¸°ë°˜ìœ¼ë¡œ í›ˆë ¨ëœ SBERT ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
# ì´ëŠ” KoELECTRAì˜ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë¬¸ì¥ ì„ë² ë”©ì— í™œìš©í•œ ëª¨ë¸ì…ë‹ˆë‹¤.
EMBEDDING_MODEL_NAME = 'snunlp/KR-SBERT-V40K-klueNLI-AS' # ê¸°ì¡´ ëª¨ë¸
# ë‹¤ë¥¸ ê°•ë ¥í•œ í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ ì˜ˆì‹œ: 'BM-K/KoSimCSE-RoBERTa-base'

# 1. ëª¨ë¸ ë° íŒŒì¼ ì„¤ì •
CSV_FILE = 'final_rag_data_combined_raw.csv'
COLLECTION_NAME = 'pet_veterinary_knowledge_electra'

# 2. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
# KoELECTRA ê¸°ë°˜ SBERT ëª¨ë¸ ë¡œë“œ
print(f"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ: {EMBEDDING_MODEL_NAME}")
try:
    model = SentenceTransformer(EMBEDDING_MODEL_NAME) 
except Exception as e:
    print(f"âŒ ì˜¤ë¥˜: ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨. {EMBEDDING_MODEL_NAME} ëª¨ë¸ì„ Hugging Faceì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("KoELECTRA ê¸°ë°˜ ëª¨ë¸ ì¤‘ SentenceTransformer í˜¸í™˜ ëª¨ë¸ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    exit()

# 3. ë°ì´í„° ë¡œë“œ
try:
    df = pd.read_csv(CSV_FILE, encoding='utf-8-sig')
except FileNotFoundError:
    print(f"âŒ ì˜¤ë¥˜: '{CSV_FILE}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì „ì²˜ë¦¬ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    exit()

# 4. Chroma DB ì´ˆê¸°í™” ë° ì»¬ë ‰ì…˜ ìƒì„±
# ë°ì´í„° ì˜êµ¬ ì €ì¥ ê²½ë¡œ ì„¤ì •
DB_PATH = "./chroma_db_electra"
client = chromadb.PersistentClient(path=DB_PATH) 
collection = client.get_or_create_collection(COLLECTION_NAME)

# ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚­ì œí•˜ê³  ìƒˆë¡œ ì‹œì‘ (ì„ íƒ ì‚¬í•­)
# collection.delete(ids=collection.get()['ids']) 

# 5. ë°ì´í„° ì„ë² ë”© ë° ì €ì¥ (ì¸ë±ì‹±)
chunks = df['RAG_Chunk'].tolist()
# ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (í•„í„°ë§ì— ì‚¬ìš©í•  ì»¬ëŸ¼)
metadata_list = df[['disease', 'department_meta', 'lifeCycle']].to_dict('records')
ids_list = [f"doc_{i}" for i in range(len(chunks))]

print(f"ì´ {len(chunks)}ê°œì˜ ì²­í¬ë¥¼ ì„ë² ë”©í•˜ê³  DBì— ì €ì¥í•©ë‹ˆë‹¤...")

# ë°ì´í„°ê°€ ë§ì„ ê²½ìš° ë°°ì¹˜(Batch) ì²˜ë¦¬ ê¶Œì¥
# 32ê°œ ë‹¨ìœ„ë¡œ ë°°ì¹˜ ì²˜ë¦¬ ì˜ˆì‹œ
batch_size = 32
for i in range(0, len(chunks), batch_size):
    batch_chunks = chunks[i:i + batch_size]
    batch_metadata = metadata_list[i:i + batch_size]
    batch_ids = ids_list[i:i + batch_size]
    
    # ì„ë² ë”© ìƒì„±
    batch_vectors = model.encode(batch_chunks, convert_to_numpy=False) # list of listsë¡œ ë³€í™˜
    
    # DBì— ì €ì¥
    collection.add(
        embeddings=batch_vectors.tolist(),
        documents=batch_chunks,
        metadatas=batch_metadata,
        ids=batch_ids
    )

print("âœ… ì§€ì‹ ê¸°ë°˜(ë²¡í„° DB) êµ¬ì¶• ì™„ë£Œ.")
print(f"ì €ì¥ëœ ì»¬ë ‰ì…˜ ì´ë¦„: {COLLECTION_NAME}, DB ê²½ë¡œ: {DB_PATH}")